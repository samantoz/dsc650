{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "\n",
    "from kafka import KafkaProducer, KafkaAdminClient\n",
    "from kafka.admin.new_topic import NewTopic\n",
    "from kafka.errors import TopicAlreadyExistsError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Parameters \n",
    "\n",
    "> **TODO:** Change the configuration prameters to the appropriate values for your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap_servers': ['kafka.kafka.svc.cluster.local:9092'],\n",
       " 'first_name': 'Arindam',\n",
       " 'last_name': 'Samanta',\n",
       " 'client_id': 'SamantaArindam',\n",
       " 'topic_prefix': 'SamantaArindam'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict(\n",
    "    bootstrap_servers=['kafka.kafka.svc.cluster.local:9092'],\n",
    "    first_name='Arindam',\n",
    "    last_name='Samanta'\n",
    ")\n",
    "\n",
    "config['client_id'] = '{}{}'.format(\n",
    "    config['last_name'], \n",
    "    config['first_name']\n",
    ")\n",
    "config['topic_prefix'] = '{}{}'.format(\n",
    "    config['last_name'], \n",
    "    config['first_name']\n",
    ")\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Topic Utility Function\n",
    "\n",
    "The `create_kafka_topic` helps create a Kafka topic based on your configuration settings.  For instance, if your first name is *John* and your last name is *Doe*, `create_kafka_topic('locations')` will create a topic with the name `DoeJohn-locations`.  The function will not create the topic if it already exists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created topic \"SamantaArindam-locations\"\n"
     ]
    }
   ],
   "source": [
    "def create_kafka_topic(topic_name, config=config, num_partitions=1, replication_factor=1):\n",
    "    bootstrap_servers = config['bootstrap_servers']\n",
    "    client_id = config['client_id']\n",
    "    topic_prefix = config['topic_prefix']\n",
    "    name = '{}-{}'.format(topic_prefix, topic_name)\n",
    "    \n",
    "    admin_client = KafkaAdminClient(\n",
    "        bootstrap_servers=bootstrap_servers, \n",
    "        client_id=client_id\n",
    "    )\n",
    "    \n",
    "    topic = NewTopic(\n",
    "        name=name,\n",
    "        num_partitions=num_partitions,\n",
    "        replication_factor=replication_factor\n",
    "    )\n",
    "\n",
    "    topic_list = [topic]\n",
    "    try:\n",
    "        admin_client.create_topics(new_topics=topic_list)\n",
    "        print('Created topic \"{}\"'.format(name))\n",
    "    except TopicAlreadyExistsError as e:\n",
    "        print('Topic \"{}\" already exists'.format(name))\n",
    "    \n",
    "create_kafka_topic('locations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kafka Producer\n",
    "\n",
    "The following code creates a `KafkaProducer` object which you can use to send Python objects that are serialized as JSON.\n",
    "\n",
    "**Note:** This producer serializes Python objects as JSON. This means that object must be JSON serializable.  As an example, Python `DateTime` values are not JSON serializable and must be converted to a string (e.g. ISO 8601) or a numeric value (e.g. a Unix timestamp) before being sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(\n",
    "  bootstrap_servers=config['bootstrap_servers'],\n",
    "  value_serializer=lambda x: json.dumps(x).encode('utf-8')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Data Function\n",
    "\n",
    "The `send_data` function sends a Python object to a Kafka topic. This function adds the `topic_prefix` to the topic so `send_data('locations', data)` sends a JSON serialized message to `DoeJohn-locations`. The function also registers callbacks to let you know if the message has been sent or if an error has occured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_send_success(record_metadata):\n",
    "    print('Message sent:\\n    Topic: \"{}\"\\n    Partition: {}\\n    Offset: {}'.format(\n",
    "        record_metadata.topic,\n",
    "        record_metadata.partition,\n",
    "        record_metadata.offset\n",
    "    ))\n",
    "    \n",
    "def on_send_error(excp):\n",
    "    print('I am an errback', exc_info=excp)\n",
    "    # handle exception\n",
    "\n",
    "def send_data(topic, data, config=config, producer=producer, msg_key=None):\n",
    "    topic_prefix = config['topic_prefix']\n",
    "    topic_name = '{}-{}'.format(topic_prefix, topic)\n",
    "    \n",
    "    if msg_key is not None:\n",
    "        key = msg_key\n",
    "    else:\n",
    "        key = uuid.uuid4().hex\n",
    "    \n",
    "    producer.send(\n",
    "        topic_name, \n",
    "        value=data,\n",
    "        key=key.encode('utf-8')\n",
    "    ).add_callback(on_send_success).add_errback(on_send_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message sent:\n",
      "    Topic: \"SamantaArindam-locations\"\n",
      "    Partition: 0\n",
      "    Offset: 0\n"
     ]
    }
   ],
   "source": [
    "example_data = dict(\n",
    "    key1='value1',\n",
    "    key2='value2'\n",
    ")\n",
    "\n",
    "send_data('locations', example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import heapq\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "endpoint_url='https://storage.budsc.midwest-datascience.com'\n",
    "s3 = s3fs.S3FileSystem(\n",
    "    anon=True,\n",
    "    client_kwargs={\n",
    "        'endpoint_url': endpoint_url\n",
    "    }\n",
    ")\n",
    "\n",
    "acceleration_columns = [\n",
    "    'offset',\n",
    "    'id',\n",
    "    'ride_id',\n",
    "    'uuid',\n",
    "    'x',\n",
    "    'y',\n",
    "    'z',\n",
    "#     't'\n",
    "]\n",
    "Acceleration = namedtuple('Acceleration', acceleration_columns)\n",
    "def read_accelerations():\n",
    "    df = pq.ParquetDataset(\n",
    "        's3://data/processed/bdd/accelerations',\n",
    "        filesystem=s3\n",
    "    ).read_pandas().to_pandas()\n",
    "    \n",
    "    df = df[acceleration_columns].sort_values(by=['offset'])\n",
    "    \n",
    "    records = [Acceleration(*record) for record in df.to_records(index=False)]\n",
    "    \n",
    "    return records\n",
    "accelerations = read_accelerations()\n",
    "\n",
    "location_columns = [\n",
    "    'offset',\n",
    "    'id',\n",
    "    'ride_id',\n",
    "    'uuid',\n",
    "    'course',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'geohash',\n",
    "    'speed',\n",
    "    'accuracy',\n",
    "#     't'\n",
    "]\n",
    "Location = namedtuple('Location', location_columns)\n",
    "def read_locations():\n",
    "    df = pq.ParquetDataset(\n",
    "        's3://data/processed/bdd/locations',\n",
    "        filesystem=s3\n",
    "    ).read_pandas().to_pandas()\n",
    "    \n",
    "    df = df[location_columns].sort_values(by=['offset'])\n",
    "    \n",
    "    records = [Location(*record) for record in df.to_records(index=False)]\n",
    "    \n",
    "    return records\n",
    "    \n",
    "locations = read_locations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
