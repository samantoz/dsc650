{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and define common helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import json\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "# import s3fs\n",
    "import pyarrow as pa\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import fastavro\n",
    "import pygeohash\n",
    "import snappy\n",
    "import jsonschema\n",
    "from jsonschema.exceptions import ValidationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the records from https://storage.budsc.midwest-datascience.com/data/processed/openflights/routes.jsonl.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "endpoint_url = 'https://storage.budsc.midwest-datascience.com'\n",
    "\n",
    "current_dir = Path(os.getcwd()).absolute()\n",
    "schema_dir = current_dir.joinpath('schemas')\n",
    "results_dir = current_dir.joinpath('results')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def read_jsonl_data():\n",
    "    s3 = s3fs.S3FileSystem(\n",
    "        anon=True,\n",
    "        client_kwargs={\n",
    "            'endpoint_url': endpoint_url\n",
    "        }\n",
    "    )\n",
    "    src_data_path = 'data/processed/openflights/routes.jsonl.gz'\n",
    "    with s3.open(src_data_path, 'rb') as f_gz:\n",
    "        with gzip.open(f_gz, 'rb') as f:\n",
    "            records = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saman\\git_repos\\dsc650\\dsc650\\assignments\\assignment03\n",
      "c:\\Users\\saman\\git_repos\\dsc650\\dsc650\\assignments\\assignment03\\schemas\n",
      "c:\\Users\\saman\\git_repos\\dsc650\\data\\processed\\openflights\\routes.jsonl.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "current_dir = Path(os.getcwd()).absolute()\n",
    "schema_dir = current_dir.joinpath('schemas')\n",
    "results_dir = current_dir.joinpath('results')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "src_data_dir = current_dir.parent.parent.parent.joinpath('data\\processed\\openflights\\\\routes.jsonl.gz')\n",
    "\n",
    "print(current_dir)\n",
    "print(schema_dir)\n",
    "print(src_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl_data():\n",
    "    with gzip.open(src_data_dir, 'rb') as f:\n",
    "            records = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the compressed zip file\n",
    "with open(src_data_dir, 'rb') as fread:\n",
    "\t# Now open the file to write to\n",
    "\tjson_out = results_dir.joinpath('routes.jsonl')\n",
    "\twith open(json_out, 'wb') as fwrite:\n",
    "\t\tfwrite.write(gzip.decompress(fread.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>src_airport</th>\n",
       "      <th>dst_airport</th>\n",
       "      <th>codeshare</th>\n",
       "      <th>equipment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'airline_id': 410, 'name': 'Aerocondor', 'ali...</td>\n",
       "      <td>{'airport_id': 2965, 'name': 'Sochi Internatio...</td>\n",
       "      <td>{'airport_id': 2990, 'name': 'Kazan Internatio...</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'airline_id': 410, 'name': 'Aerocondor', 'ali...</td>\n",
       "      <td>{'airport_id': 2966, 'name': 'Astrakhan Airpor...</td>\n",
       "      <td>{'airport_id': 2990, 'name': 'Kazan Internatio...</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'airline_id': 410, 'name': 'Aerocondor', 'ali...</td>\n",
       "      <td>{'airport_id': 2966, 'name': 'Astrakhan Airpor...</td>\n",
       "      <td>{'airport_id': 2962, 'name': 'Mineralnyye Vody...</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'airline_id': 410, 'name': 'Aerocondor', 'ali...</td>\n",
       "      <td>{'airport_id': 2968, 'name': 'Chelyabinsk Bala...</td>\n",
       "      <td>{'airport_id': 2990, 'name': 'Kazan Internatio...</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'airline_id': 410, 'name': 'Aerocondor', 'ali...</td>\n",
       "      <td>{'airport_id': 2968, 'name': 'Chelyabinsk Bala...</td>\n",
       "      <td>{'airport_id': 4078, 'name': 'Tolmachevo Airpo...</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             airline  \\\n",
       "0  {'airline_id': 410, 'name': 'Aerocondor', 'ali...   \n",
       "1  {'airline_id': 410, 'name': 'Aerocondor', 'ali...   \n",
       "2  {'airline_id': 410, 'name': 'Aerocondor', 'ali...   \n",
       "3  {'airline_id': 410, 'name': 'Aerocondor', 'ali...   \n",
       "4  {'airline_id': 410, 'name': 'Aerocondor', 'ali...   \n",
       "\n",
       "                                         src_airport  \\\n",
       "0  {'airport_id': 2965, 'name': 'Sochi Internatio...   \n",
       "1  {'airport_id': 2966, 'name': 'Astrakhan Airpor...   \n",
       "2  {'airport_id': 2966, 'name': 'Astrakhan Airpor...   \n",
       "3  {'airport_id': 2968, 'name': 'Chelyabinsk Bala...   \n",
       "4  {'airport_id': 2968, 'name': 'Chelyabinsk Bala...   \n",
       "\n",
       "                                         dst_airport  codeshare equipment  \n",
       "0  {'airport_id': 2990, 'name': 'Kazan Internatio...      False     [CR2]  \n",
       "1  {'airport_id': 2990, 'name': 'Kazan Internatio...      False     [CR2]  \n",
       "2  {'airport_id': 2962, 'name': 'Mineralnyye Vody...      False     [CR2]  \n",
       "3  {'airport_id': 2990, 'name': 'Kazan Internatio...      False     [CR2]  \n",
       "4  {'airport_id': 4078, 'name': 'Tolmachevo Airpo...      False     [CR2]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrecords = read_jsonl_data()\n",
    "# print(type(myrecords))\n",
    "df_list = pd.DataFrame(myrecords)\n",
    "df_list.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airline_id': 410,\n",
       " 'name': 'Aerocondor',\n",
       " 'alias': 'ANA All Nippon Airways',\n",
       " 'iata': '2B',\n",
       " 'icao': 'ARD',\n",
       " 'callsign': 'AEROCONDOR',\n",
       " 'country': 'Portugal',\n",
       " 'active': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list['airline'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_id</th>\n",
       "      <th>name</th>\n",
       "      <th>alias</th>\n",
       "      <th>iata</th>\n",
       "      <th>icao</th>\n",
       "      <th>callsign</th>\n",
       "      <th>country</th>\n",
       "      <th>active</th>\n",
       "      <th>airport_id</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>altitude</th>\n",
       "      <th>timezone</th>\n",
       "      <th>dst</th>\n",
       "      <th>tz_id</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "      <th>codeshare</th>\n",
       "      <th>equipment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>Aerocondor</td>\n",
       "      <td>ANA All Nippon Airways</td>\n",
       "      <td>2B</td>\n",
       "      <td>ARD</td>\n",
       "      <td>AEROCONDOR</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>True</td>\n",
       "      <td>2965.0</td>\n",
       "      <td>Sochi International Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>55.606201</td>\n",
       "      <td>49.278702</td>\n",
       "      <td>411.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Europe/Moscow</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>410</td>\n",
       "      <td>Aerocondor</td>\n",
       "      <td>ANA All Nippon Airways</td>\n",
       "      <td>2B</td>\n",
       "      <td>ARD</td>\n",
       "      <td>AEROCONDOR</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>True</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>Astrakhan Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>55.606201</td>\n",
       "      <td>49.278702</td>\n",
       "      <td>411.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Europe/Moscow</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>410</td>\n",
       "      <td>Aerocondor</td>\n",
       "      <td>ANA All Nippon Airways</td>\n",
       "      <td>2B</td>\n",
       "      <td>ARD</td>\n",
       "      <td>AEROCONDOR</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>True</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>Astrakhan Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>44.225101</td>\n",
       "      <td>43.081902</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Europe/Moscow</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>410</td>\n",
       "      <td>Aerocondor</td>\n",
       "      <td>ANA All Nippon Airways</td>\n",
       "      <td>2B</td>\n",
       "      <td>ARD</td>\n",
       "      <td>AEROCONDOR</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>True</td>\n",
       "      <td>2968.0</td>\n",
       "      <td>Chelyabinsk Balandino Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>55.606201</td>\n",
       "      <td>49.278702</td>\n",
       "      <td>411.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Europe/Moscow</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>410</td>\n",
       "      <td>Aerocondor</td>\n",
       "      <td>ANA All Nippon Airways</td>\n",
       "      <td>2B</td>\n",
       "      <td>ARD</td>\n",
       "      <td>AEROCONDOR</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>True</td>\n",
       "      <td>2968.0</td>\n",
       "      <td>Chelyabinsk Balandino Airport</td>\n",
       "      <td>...</td>\n",
       "      <td>55.012600</td>\n",
       "      <td>82.650703</td>\n",
       "      <td>365.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Asia/Krasnoyarsk</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline_id        name                   alias iata icao    callsign  \\\n",
       "0         410  Aerocondor  ANA All Nippon Airways   2B  ARD  AEROCONDOR   \n",
       "1         410  Aerocondor  ANA All Nippon Airways   2B  ARD  AEROCONDOR   \n",
       "2         410  Aerocondor  ANA All Nippon Airways   2B  ARD  AEROCONDOR   \n",
       "3         410  Aerocondor  ANA All Nippon Airways   2B  ARD  AEROCONDOR   \n",
       "4         410  Aerocondor  ANA All Nippon Airways   2B  ARD  AEROCONDOR   \n",
       "\n",
       "    country  active  airport_id                           name  ...  \\\n",
       "0  Portugal    True      2965.0    Sochi International Airport  ...   \n",
       "1  Portugal    True      2966.0              Astrakhan Airport  ...   \n",
       "2  Portugal    True      2966.0              Astrakhan Airport  ...   \n",
       "3  Portugal    True      2968.0  Chelyabinsk Balandino Airport  ...   \n",
       "4  Portugal    True      2968.0  Chelyabinsk Balandino Airport  ...   \n",
       "\n",
       "    latitude  longitude altitude timezone  dst             tz_id     type  \\\n",
       "0  55.606201  49.278702    411.0      3.0    N     Europe/Moscow  airport   \n",
       "1  55.606201  49.278702    411.0      3.0    N     Europe/Moscow  airport   \n",
       "2  44.225101  43.081902   1054.0      3.0    N     Europe/Moscow  airport   \n",
       "3  55.606201  49.278702    411.0      3.0    N     Europe/Moscow  airport   \n",
       "4  55.012600  82.650703    365.0      7.0    N  Asia/Krasnoyarsk  airport   \n",
       "\n",
       "        source codeshare equipment  \n",
       "0  OurAirports     False     [CR2]  \n",
       "1  OurAirports     False     [CR2]  \n",
       "2  OurAirports     False     [CR2]  \n",
       "3  OurAirports     False     [CR2]  \n",
       "4  OurAirports     False     [CR2]  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airline = pd.json_normalize(df_list['airline'])\n",
    "df_src_airport = pd.json_normalize(df_list['src_airport'])\n",
    "df_dst_airport = pd.json_normalize(df_list['dst_airport'])\n",
    "df_final = pd.concat([df_airline,df_src_airport,df_dst_airport,df_list['codeshare'],df_list['equipment']], axis=1)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = read_jsonl_data()\n",
    "records_file = results_dir.joinpath('records_txt.txt')\n",
    "with open(records_file, 'w') as f:\n",
    "\tjson.dump(records,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.a JSON Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def validate_jsonl_data(records):\n",
    "    schema_path = schema_dir.joinpath('routes-schema.json')\n",
    "    with open(schema_path) as f:\n",
    "        schema = json.load(f)\n",
    "    validation_csv_path = results_dir.joinpath('validate_json.csv')    \n",
    "    with open(validation_csv_path, 'w') as f:    \n",
    "        for i, record in enumerate(records):\n",
    "            try:\n",
    "                ## TODO: Validate record \n",
    "                jsonschema.validate(instance=record, schema=schema)\n",
    "            except ValidationError as e:\n",
    "                ## Print message if invalid record\n",
    "                pass\n",
    "            \n",
    "validate_jsonl_data(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_jsonl_data(jsondata):\n",
    "\t\"\"\"This function loads the given schema available\"\"\"\n",
    "\tschema_path = schema_dir.joinpath('routes-schema.json')\n",
    "\tfname = Path(schema_path).name\n",
    "\t# print(fname)\n",
    "\t# print(schema_path)\n",
    "\t# return fname\n",
    "\twith open(fname, 'r') as fsch:\n",
    "\t\tschema = json.load(fsch)\n",
    "\tvalidation_csv_path = results_dir.joinpath('validate_json.csv')\n",
    "\twith open(validation_csv_path, 'w') as fwrite:\n",
    "\t\tfor i, record in enumerate(jsondata):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tjsonschema.validate(instance=record, schema=schema)\n",
    "\t\t\texcept jsonschema.exceptions.ValidationError as err:\n",
    "\t\t\t\terr = f'Error in {i}-record'\n",
    "\t\t\t\tfwrite.write(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "routes-schema.json\n",
      "c:\\Users\\saman\\git_repos\\dsc650\\dsc650\\assignments\\assignment03\\schemas\\routes-schema.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'routes-schema.json'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_jsonl_data('jj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'routes-schema.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-52de4093282b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# samplejson_path = results_dir.joinpath('')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# samplejson = Path(samplejson_path).name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvalidate_jsonl_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sample.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-41-17b15c569753>\u001b[0m in \u001b[0;36mvalidate_jsonl_data\u001b[1;34m(jsondata)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mschema_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mschema_dir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'routes-schema.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mschema_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfsch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                 \u001b[0mschema\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfsch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mvalidation_csv_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_dir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'validate_json.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'routes-schema.json'"
     ]
    }
   ],
   "source": [
    "# samplejson_path = results_dir.joinpath('')\n",
    "# samplejson = Path(samplejson_path).name\n",
    "validate_jsonl_data('sample.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.b Avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'myrecords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-f81ab7ffb8f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mcreate_avro_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'myrecords' is not defined"
     ]
    }
   ],
   "source": [
    "from fastavro import writer, reader, parse_schema\n",
    "\n",
    "def create_avro_dataset(records):\n",
    "    schema_path = schema_dir.joinpath('routes.avsc')\n",
    "    data_path = results_dir.joinpath('routes.avro')\n",
    "\n",
    "\n",
    "    ## TODO: Use fastavro to create Avro dataset\n",
    "    with open(schema_path) as f:\n",
    "        schema = json.load(f)\n",
    "        parsed_schema = parse_schema(schema)\n",
    "\n",
    "    # writing\n",
    "    with open(data_path, 'w') as f:    \n",
    "        for i, record in enumerate(records):\n",
    "            try:\n",
    "                ## TODO: Validate record \n",
    "                # writer(f, parsed_schema,record)\n",
    "                print(i,record)\n",
    "            except ValidationError as e:\n",
    "                ## Print message if invalid record\n",
    "                pass\n",
    "        \n",
    "create_avro_dataset(myrecords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'records' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-033bd7a175d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mcreate_avro_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'records' is not defined"
     ]
    }
   ],
   "source": [
    "from fastavro import writer, reader, parse_schema\n",
    "\n",
    "def create_avro_dataset(records):\n",
    "    schema_path = schema_dir.joinpath('routes.avsc')\n",
    "    data_path = results_dir.joinpath('routes.avro')\n",
    "\n",
    "\n",
    "    ## TODO: Use fastavro to create Avro dataset\n",
    "    with open(schema_path) as f:\n",
    "        schema = json.load(f)\n",
    "        parsed_schema = parse_schema(schema)\n",
    "\n",
    "    # writing\n",
    "    with open(data_path, 'wb') as f:\n",
    "            try:\n",
    "                ## TODO: Validate record \n",
    "                writer(f, parsed_schema,records)\n",
    "                # print(i,record)\n",
    "            except ValidationError as e:\n",
    "                ## Print message if invalid record\n",
    "                pass\n",
    "        \n",
    "create_avro_dataset(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.c Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parquet_dataset():\n",
    "    src_data_path = 'data/processed/openflights/routes.jsonl.gz'\n",
    "    parquet_output_path = results_dir.joinpath('routes.parquet')\n",
    "    s3 = s3fs.S3FileSystem(\n",
    "        anon=True,\n",
    "        client_kwargs={\n",
    "            'endpoint_url': endpoint_url\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    with s3.open(src_data_path, 'rb') as f_gz:\n",
    "        with gzip.open(f_gz, 'rb') as f:\n",
    "            pass\n",
    "            ## TODO: Use Apache Arrow to create Parquet table and save the dataset\n",
    "\n",
    "create_parquet_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>src_airport</th>\n",
       "      <th>dst_airport</th>\n",
       "      <th>codeshare</th>\n",
       "      <th>equipment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'airline_id': 410, 'name': 'Aerocondor', 'ali...</td>\n",
       "      <td>{'airport_id': 2965, 'name': 'Sochi Internatio...</td>\n",
       "      <td>{'airport_id': 2990, 'name': 'Kazan Internatio...</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'airline_id': 410, 'name': 'Aerocondor', 'ali...</td>\n",
       "      <td>{'airport_id': 2966, 'name': 'Astrakhan Airpor...</td>\n",
       "      <td>{'airport_id': 2990, 'name': 'Kazan Internatio...</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'airline_id': 410, 'name': 'Aerocondor', 'ali...</td>\n",
       "      <td>{'airport_id': 2966, 'name': 'Astrakhan Airpor...</td>\n",
       "      <td>{'airport_id': 2962, 'name': 'Mineralnyye Vody...</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'airline_id': 410, 'name': 'Aerocondor', 'ali...</td>\n",
       "      <td>{'airport_id': 2968, 'name': 'Chelyabinsk Bala...</td>\n",
       "      <td>{'airport_id': 2990, 'name': 'Kazan Internatio...</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'airline_id': 410, 'name': 'Aerocondor', 'ali...</td>\n",
       "      <td>{'airport_id': 2968, 'name': 'Chelyabinsk Bala...</td>\n",
       "      <td>{'airport_id': 4078, 'name': 'Tolmachevo Airpo...</td>\n",
       "      <td>False</td>\n",
       "      <td>[CR2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             airline  \\\n",
       "0  {'airline_id': 410, 'name': 'Aerocondor', 'ali...   \n",
       "1  {'airline_id': 410, 'name': 'Aerocondor', 'ali...   \n",
       "2  {'airline_id': 410, 'name': 'Aerocondor', 'ali...   \n",
       "3  {'airline_id': 410, 'name': 'Aerocondor', 'ali...   \n",
       "4  {'airline_id': 410, 'name': 'Aerocondor', 'ali...   \n",
       "\n",
       "                                         src_airport  \\\n",
       "0  {'airport_id': 2965, 'name': 'Sochi Internatio...   \n",
       "1  {'airport_id': 2966, 'name': 'Astrakhan Airpor...   \n",
       "2  {'airport_id': 2966, 'name': 'Astrakhan Airpor...   \n",
       "3  {'airport_id': 2968, 'name': 'Chelyabinsk Bala...   \n",
       "4  {'airport_id': 2968, 'name': 'Chelyabinsk Bala...   \n",
       "\n",
       "                                         dst_airport  codeshare equipment  \n",
       "0  {'airport_id': 2990, 'name': 'Kazan Internatio...      False     [CR2]  \n",
       "1  {'airport_id': 2990, 'name': 'Kazan Internatio...      False     [CR2]  \n",
       "2  {'airport_id': 2962, 'name': 'Mineralnyye Vody...      False     [CR2]  \n",
       "3  {'airport_id': 2990, 'name': 'Kazan Internatio...      False     [CR2]  \n",
       "4  {'airport_id': 4078, 'name': 'Tolmachevo Airpo...      False     [CR2]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_jsonl = current_dir.joinpath('sample.json')\n",
    "routes_jsonl = results_dir.joinpath('routes.jsonl')\n",
    "\n",
    "df = pd.read_json(routes_jsonl,lines=True, orient='columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          410\n",
       "1          410\n",
       "2          410\n",
       "3          410\n",
       "4          410\n",
       "         ...  \n",
       "67658     4178\n",
       "67659    19016\n",
       "67660    19016\n",
       "67661    19016\n",
       "67662    19016\n",
       "Name: airline_id, Length: 67663, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parquet_output_path = results_dir.joinpath('routes.parquet')\n",
    "input_jsonl = current_dir.joinpath('sample.json')\n",
    "routes_jsonl = results_dir.joinpath('routes.jsonl')\n",
    "\n",
    "df = pd.read_json(routes_jsonl,lines=True, orient='columns')\n",
    "df.head()\n",
    "bn = pd.DataFrame(df.airline.values.tolist())['airline_id']\n",
    "bn\n",
    "# table = pd.DataFrame(records)\n",
    "# table = pa.Table.from_pandas(table)\n",
    "# pq.write_table(table, 'file.parquet')\n",
    "# pd.json_normalize(bn).head()\n",
    "\n",
    "# table = pa.Table.from_pandas(df)\n",
    "# pq.write_table(table, 'routes.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saman\\git_repos\\dsc650\\dsc650\\assignments\\assignment03\\results\\routes.jsonl\n",
      "routes.jsonl\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2a14ca16c957>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroutes_jsonl_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdatafile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatafile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mww\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not iterable"
     ]
    }
   ],
   "source": [
    "routes_jsonl_path = results_dir.joinpath('routes.jsonl')\n",
    "print(routes_jsonl_path)\n",
    "file_name = Path(routes_jsonl_path).name\n",
    "print(file_name)\n",
    "with open(routes_jsonl_path) as datafile:\n",
    "\tfor line in datafile.readline:\n",
    "\t\tdata = json.loads(line)\n",
    "\tww = pd.DataFrame(data)\n",
    "\n",
    "ww.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.d Protocol Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath('routes_pb2'))\n",
    "\n",
    "import routes_pb2\n",
    "\n",
    "def _airport_to_proto_obj(airport):\n",
    "    obj = routes_pb2.Airport()\n",
    "    if airport is None:\n",
    "        return None\n",
    "    if airport.get('airport_id') is None:\n",
    "        return None\n",
    "\n",
    "    obj.airport_id = airport.get('airport_id')\n",
    "    if airport.get('name'):\n",
    "        obj.name = airport.get('name')\n",
    "    if airport.get('city'):\n",
    "        obj.city = airport.get('city')\n",
    "    if airport.get('iata'):\n",
    "        obj.iata = airport.get('iata')\n",
    "    if airport.get('icao'):\n",
    "        obj.icao = airport.get('icao')\n",
    "    if airport.get('altitude'):\n",
    "        obj.altitude = airport.get('altitude')\n",
    "    if airport.get('timezone'):\n",
    "        obj.timezone = airport.get('timezone')\n",
    "    if airport.get('dst'):\n",
    "        obj.dst = airport.get('dst')\n",
    "    if airport.get('tz_id'):\n",
    "        obj.tz_id = airport.get('tz_id')\n",
    "    if airport.get('type'):\n",
    "        obj.type = airport.get('type')\n",
    "    if airport.get('source'):\n",
    "        obj.source = airport.get('source')\n",
    "\n",
    "    obj.latitude = airport.get('latitude')\n",
    "    obj.longitude = airport.get('longitude')\n",
    "\n",
    "    return obj\n",
    "\n",
    "\n",
    "def _airline_to_proto_obj(airline):\n",
    "    obj = routes_pb2.Airline()\n",
    "    ## TODO: Create an Airline obj using Protocol Buffers API\n",
    "    return obj\n",
    "\n",
    "\n",
    "def create_protobuf_dataset(records):\n",
    "    routes = routes_pb2.Routes()\n",
    "    for record in records:\n",
    "        route = routes_pb2.Route()\n",
    "        ## TODO: Implement the code to create the Protocol Buffers Dataset\n",
    "\n",
    "        routes.route.append(route)\n",
    "\n",
    "    data_path = results_dir.joinpath('routes.pb')\n",
    "\n",
    "    with open(data_path, 'wb') as f:\n",
    "        f.write(routes.SerializeToString())\n",
    "        \n",
    "    compressed_path = results_dir.joinpath('routes.pb.snappy')\n",
    "    \n",
    "    with open(compressed_path, 'wb') as f:\n",
    "        f.write(snappy.compress(routes.SerializeToString()))\n",
    "        \n",
    "create_protobuf_dataset(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.a Simple Geohash Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hash_dirs(records):\n",
    "    geoindex_dir = results_dir.joinpath('geoindex')\n",
    "    geoindex_dir.mkdir(exist_ok=True, parents=True)\n",
    "    hashes = []\n",
    "    ## TODO: Create hash index\n",
    "            \n",
    "create_hash_dirs(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-56-0a5d8fad30da>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-56-0a5d8fad30da>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    hashes.sort()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# Assignment 3.2.a\n",
    "def create_hash_dirs(records):\n",
    "    geoindex_dir = results_dir.joinpath('geoindex')\n",
    "    geoindex_dir.mkdir(exist_ok=True, parents=True)\n",
    "    hashes = []\n",
    "    for record in records:\n",
    "        src_airport = record.get('src_airport', {})\n",
    "        if src_airport:\n",
    "            latitude = src_airport.get('latitude')\n",
    "            longitude = src_airport.get('longitude')\n",
    "            if latitude and longitude:\n",
    "                ## TODO: use pygeohash.encode() to assign geohashes to the records and complete the hashes list\n",
    "    hashes.sort()\n",
    "    three_letter = sorted(list(set([entry[:3] for entry in hashes])))\n",
    "    hash_index = {value: [] for value in three_letter}\n",
    "    for record in records:\n",
    "        geohash = record.get('geohash')\n",
    "        if geohash:\n",
    "            hash_index[geohash[:3]].append(record)\n",
    "    for key, values in hash_index.items():\n",
    "        output_dir = geoindex_dir.joinpath(str(key[:1])).joinpath(str(key[:2]))\n",
    "        output_dir.mkdir(exist_ok=True, parents=True)\n",
    "        output_path = output_dir.joinpath('{}.jsonl.gz'.format(key))\n",
    "        with gzip.open(output_path, 'w') as f:\n",
    "            json_output = '\\n'.join([json.dumps(value) for value in values])\n",
    "            f.write(json_output.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.b Simple Search Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def airport_search(latitude, longitude):\n",
    "    ## TODO: Create simple search to return nearest airport\n",
    "    pass\n",
    "    \n",
    "airport_search(41.1499988, -95.91779)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
